{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMPLE KRIGING IN PYTHON - 1D Application for a Single Point\n",
    "\n",
    "### Note:\n",
    "\n",
    "*This Notebook is based on an original Post from Connor Johnson, the original post is found here:\n",
    "http://connor-johnson.com/2014/03/20/simple-kriging-in-python/. It has been transferred to a Jupyter Notebook to make it more interactive.*\n",
    "\n",
    "*Changes being made:*\n",
    "+ *using a common variogram function*\n",
    "+ *calculation of variance map* \n",
    "+ *some code structure*\n",
    "\n",
    "*The example data is modified to represent a quasi-1D distribution (along the x-axis), to improve comprehensibility. Visualisation has been changed to consider this, and puts an additional focus on the uncertainty of the prediction*\n",
    "\n",
    "*The Kriging Method has been further broken up into its elementary steps to allow better understanding and the facilitates further developments. Accordingly, this Notebook only estimates and visualises a single point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Post\n",
    "\n",
    "In this post I will work through an example of Simple Kriging. Kriging is a set of techniques for interpolation. It differs from other interpolation techniques in that it sacrifices smoothness for the integrity of sampled points. Most interpolation techniques will over or undershoot the value of the function at sampled locations, but kriging honors those measurements and keeps them fixed. In future posts I would like to cover other types of kriging, other semivariaogram models, and colocated co-kriging. Until then, I’m keeping relatively up to date code at my GitHub project, geostatsmodels. (https://github.com/cjohnson318/geostatsmodels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "import numpy as np\n",
    "from pandas import DataFrame, Series\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['figure.figsize'] = [16 / 1.5, 10 / 1.5]   # inch / cm = 2.54\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['savefig.bbox'] = 'tight'\n",
    "# plt.rcParams['savefig.frameon'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "The data used in this exercise is in a zip file at this site. (Click on Geostatistics Resources.) I have adapted my material from the Kriging document on the same site. My approach will focus more on programming. First we will import some modules and then load the data and parse it,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zraw = open( 'example_data/ZoneA.dat','r' ).readlines()\n",
    "zraw = [ i.strip().split() for i in zraw[10:] ]\n",
    "zraw = np.array( zraw, dtype=np.float )\n",
    "zraw = DataFrame( zraw, columns=['x','y','thk','por','perm','lperm','lpermp','lpermr'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a sub-set and reduce to Quasi-1D\n",
    "\n",
    "For this exercise, we need to reduce the data, and only choose values within a certain intervall for y, and create a quasi-1D Dataset by zeroing the y-coordinate. This is necessary as the method may fail during matrix inversion if there are two points with (near) equal x-coordinates, leading to a singular matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the data subset from a y-intervall\n",
    "ymean = 7500\n",
    "yinterval = 2000\n",
    "\n",
    "z = zraw  # create copy of full data set\n",
    "\n",
    "# show the intervall before reducing the data\n",
    "fig, ax = subplots()\n",
    "ax.scatter( z.x, z.y, c=z.por, cmap='gray' )\n",
    "ax.plot((-1500,22000),(ymean - yinterval / 2, ymean - yinterval / 2), \"r--\")\n",
    "ax.plot((-1500,22000),(ymean + yinterval / 2, ymean + yinterval / 2), \"r--\")\n",
    "ax.plot((-1500,22000),(ymean, ymean), \"r-\")\n",
    "ax.set_aspect(1)\n",
    "xlim(-1500,22000)\n",
    "ylim(-1500,17500)\n",
    "xlabel('Easting [m]')\n",
    "ylabel('Northing [m]')\n",
    "title('Porosity %') ;\n",
    "\n",
    "plt.show()\n",
    "\n",
    "z = z.loc[z.y > ymean - yinterval / 2]\n",
    "z = z.loc[z.y < ymean + yinterval / 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce to quasi 1-D by assigning zero as y-coordinates for all samples,\n",
    "# and sort the array by x-coordinate for better plottability.\n",
    "\n",
    "z.y = 0.\n",
    "z = z.sort_values(by=\"x\")\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.scatter( z.x, z.y, c=z.por, cmap='gray' )\n",
    "ylabel('Northing [m]')\n",
    "title('Porosity %') ;\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(z.x, z.por, \".--\")\n",
    "ylabel('Value')\n",
    "xlabel('Easting [m]')\n",
    "plt.show()\n",
    "\n",
    "# part of our data set recording porosity\n",
    "P = np.array( z[['x','y','por']] )\n",
    "print(\"P =\")\n",
    "print(P)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Semivariogram\n",
    "\n",
    "The semivariogram encodes data about spatial variance over the region at a given distance or lag. We generally expect data points that are close together spatially to share other characteristics, and we expect points that are separated by greater distances to have lesser correlation. The semivariogram allows us to model the similarity points in a field as a function of distance. The semivariogram is given by,\n",
    "\n",
    "$$\\begin{equation*} \\hat{\\gamma}(h) = \\dfrac{1}{2N(h)} \\displaystyle \\sum_{N(h)} ( z_{i} - z_{j} )^{2} \\end{equation*}$$ (Equation 1)\n",
    "\n",
    "Here, h is distance specified by the user, and z_{i} and z_{j} are two points that are separated spatially by h. The N(h) term is the number of points we have that are separated by the distance h. The semivariogram then is the sum of squared differences between values separated by a distance h. As an aside, contrast this with the formulation for variance,\n",
    "\n",
    "$$\\begin{equation*} s = \\dfrac{1}{N-1} \\displaystyle \\sum_{k=1}^{N} (z_{k} - \\hat{\\mu} )^{2} \\end{equation*}$$ (Equation 2)\n",
    "\n",
    "Here, $N$ is the number of data points, $\\hat{\\mu}$ is the sample mean, and $z_{k}$ is a data point. For sample variance, we are taking the squared difference between data points and the mean, and in the semivariogram we are taking the squared difference between data points separated by distance h. We can write some functions to calculate the semivariogram at one lag, and then at multiple lags as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVh( P, h, bw ):\n",
    "    '''\n",
    "    Experimental semivariogram for a single lag\n",
    "    '''\n",
    "    pd = squareform( pdist( P[:,:2] ) )\n",
    "    N = pd.shape[0]\n",
    "    Z = list()\n",
    "    for i in range(N):\n",
    "        for j in range(i+1,N):\n",
    "            if( pd[i,j] >= h-bw )and( pd[i,j] <= h+bw ):\n",
    "                Z.append( ( P[i,2] - P[j,2] )**2.0 )\n",
    "    return np.sum( Z ) / ( 2.0 * len( Z ) )\n",
    " \n",
    "def SV( P, hs, bw ):\n",
    "    '''\n",
    "    Experimental variogram for a collection of lags\n",
    "    '''\n",
    "    sv = list()\n",
    "    for h in hs:\n",
    "        sv.append( SVh( P, h, bw ) )\n",
    "    sv = [ [ hs[i], sv[i] ] for i in range( len( hs ) ) if sv[i] > 0 ]\n",
    "    return np.array( sv ).T\n",
    " \n",
    "def C( P, h, bw ):\n",
    "    '''\n",
    "    Calculate the sill\n",
    "    '''\n",
    "    c0 = np.var( P[:,2] )\n",
    "    if h == 0:\n",
    "        return c0\n",
    "    return c0 - SVh( P, h, bw )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The C() function is the covariance function, and will be used later. Let us now calculate and plot the semivariogram,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bandwidth, plus or minus 250 meters\n",
    "bw = 500\n",
    "# lags in 500 meter increments from zero to 10,000\n",
    "hs = np.arange(0,10500,bw)\n",
    "sv = SV( P, hs, bw )\n",
    "plot( sv[0], sv[1], '.-' )\n",
    "xlabel('Lag [m]')\n",
    "ylabel('Semivariance')\n",
    "title('Empirical Semivariogram') ;\n",
    "savefig('sample_semivariogram.png', fmt='png', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling\n",
    "Now that we’ve calculated the semivariogram, we will need to fit a model to the data. There are three popular models, the spherical, exponential, and the Gaussian. Here, we’ll implement the spherical model. First, we will present a function named opt() for determining the optimal value a for the spherical model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt( fct, x, y, C0, parameterRange=None, meshSize=1000 ):\n",
    "    if parameterRange == None:\n",
    "        parameterRange = [ x[1], x[-1] ]\n",
    "    mse = np.zeros( meshSize )\n",
    "    a = np.linspace( parameterRange[0], parameterRange[1], meshSize )\n",
    "    for i in range( meshSize ):\n",
    "        mse[i] = np.mean( ( y - fct( x, a[i], C0 ) )**2.0 )\n",
    "    return a[ mse.argmin() ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The opt() function finds the optimal parameter for fitting a spherical model to the semivariogram data. The spherical model is given by the function spherical(). On the last line we see that spherical() returns itself in a map() function, which seems odd. The idea is that the input h can be a single float value, or list or NumPy array of floats. If h is a single value, then line 9 is called. If h is a list or an array (an iterable) then line 17 is called, which applies line 9 to each value of h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import svmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, cvmodel() fits a model to the semivariogram data and returns a covariance method named covfct()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvmodel( P, model, hs, bw, Cn=None ):\n",
    "    '''\n",
    "    Input:  (P)      ndarray, data\n",
    "            (model)  modeling function\n",
    "                      - spherical\n",
    "                      - exponential\n",
    "                      - gaussian\n",
    "            (hs)     distances\n",
    "            (bw)     bandwidth\n",
    "    Output: (covfct) function modeling the covariance\n",
    "    '''\n",
    "    if Cn is None:\n",
    "        Cn = 0\n",
    "    # calculate the semivariogram\n",
    "    sv = SV( P, hs, bw )\n",
    "    # calculate the sill\n",
    "    C0 = C( P, hs[0], bw )\n",
    "    # calculate the optimal parameters\n",
    "    param = opt( model, sv[0], sv[1], C0 )\n",
    "    # return a covariance function\n",
    "    covfct = lambda h, a=param: C0 - list(model( h, a, C0, Cn=Cn ))\n",
    "    return covfct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we’ll plot our model and see if it represents our data well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = cvmodel( P, model=svmodels.spherical, hs=np.arange(0,10500,500), bw=500, Cn=0.1 )\n",
    "C0 = C( P, hs[0], bw )\n",
    "plot( sv[0], sv[1], '.-' )\n",
    "plot( sv[0], C0 - sp( sv[0] ) ) ;\n",
    "title('Spherical Model')\n",
    "ylabel('Semivariance')\n",
    "xlabel('Lag [m]')\n",
    "savefig('semivariogram_model.png',fmt='png',dpi=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Kriging\n",
    "\n",
    "\n",
    "Now that we have a model for the semivariogram, we can write a function to perform the kriging. The fundamental relationship is a matrix equation,\n",
    "\n",
    "$$\\begin{equation*} K \\lambda = k \\Rightarrow \\lambda = K^{-1} k \\end{equation*} $$ \n",
    "\n",
    "Here, $K$ is a matrix of covariances of sampled data points, calculated using the spherical model, $\\lambda$ is a vector of simple kriging weights, and $k$ is the vector of covariances between the data points and an unsampled point. Our kriging function takes the data set $P$, the model, the distances hs, the bandwidth bw, the coordinates of the unsampled point u, and the number of surrounding points N to use in the calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h, k, K, weights = krige( P, sp, (dy*j,dx*i), len(z) / 2 )       \n",
    "# PARAMETER DEFINITION\n",
    "#           (P)     data set [y,x,value]\n",
    "#           (model) modeling function\n",
    "#                    - spherical\n",
    "#                    - exponential\n",
    "#                    - gaussian\n",
    "#           (u)     unsampled point\n",
    "#           (N)     number of neighboring\n",
    "#                   points to consider\n",
    "\n",
    "# P - Data set already defined\n",
    "covfct = sp  # covariance function\n",
    "u = (7900, 0)  # (x,y) - coordinates of unsampled points\n",
    "N = 5  # number of neighbors to consider\n",
    "assert N < len(P) + 1, \"Number of Neighbors greater than number of data points\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing the Kriging Process for a single point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean of the variable\n",
    "mu = np.mean( P[:,2] )\n",
    "print(\"mu = \" + str(mu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance between the unsampled point $u$ and each data point in $P$ is calculated, creating a vector $d$ of size 1xM, where M is the number of data points.\n",
    "\n",
    "This vector becomes an additional column to the matric $P$, which allows to sort the rows of $P$ by their distance to the data point, and only selecting to closest N neighbors.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance between u and each data point in P (1xN vector)\n",
    "d = np.sqrt( ( P[:,0]-u[0] )**2.0 + ( P[:,1]-u[1] )**2.0 )  # 2D \n",
    "print(\"d = \"+str(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add these distances to P\n",
    "P_n = np.vstack(( P.T, d )).T\n",
    "# sort P by these distances\n",
    "# take the first N of them\n",
    "P_n = P_n[d.argsort()[:N]]\n",
    "print(\"P_n = \\n\" + str(P_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the remaining points, the expected covariance between the point and the unsampled point $u$ is calculated based on its distance by the convariance function\n",
    "\n",
    "$$k = cov(d)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the covariance model to the distances\n",
    "k = covfct( P_n[:,3] )\n",
    "# cast as a matrix\n",
    "k = np.matrix( k ).T\n",
    "print(\"k =\\n\" + str(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the covariance matrix $K$ with the covariances of all sampled points, the same function is being used:\n",
    "\n",
    "$$K = [cov(d_{ij})]$$\n",
    "\n",
    "with $d_{ij}$ being the Euclidian distance between points $i$ and $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a matrix of distances between existing data points\n",
    "K = squareform( pdist( P_n[:,:2] ) )\n",
    "# apply the covariance model to these distances\n",
    "K = covfct( K.ravel() )\n",
    "# re-cast as a NumPy array -- thanks M.L.\n",
    "K = np.array( K )\n",
    "# reshape into an array\n",
    "K = K.reshape(N,N)\n",
    "# cast as a matrix\n",
    "K = np.matrix( K )\n",
    "print(\"K =\\n\"+str(K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this allows calculating the Kriging weights $\\lambda$ as defined previously\n",
    "\n",
    "$$\\lambda = K^{-1} k$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"K-1 =\\n\"+str(np.linalg.inv( K )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the kriging weights\n",
    "weights = np.linalg.inv( K ) * k\n",
    "weights = np.array( weights )\n",
    "print(\"weights =\\n\"+str(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\epsilon = P[:,2] - \\mu$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the residuals\n",
    "residuals = P_n[:,2] - mu\n",
    "print(\"residuals = \"+str(residuals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$e(u) =\\lambda^T \\cdot \\epsilon + \\mu $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the estimation\n",
    "estimation = np.dot( weights.T, residuals ) + mu\n",
    "print(\"estimation = \"+str(estimation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sigma^2 = C_0 - \\lambda^T \\cdot k$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = C0 - np.dot( weights.T, k )\n",
    "print(\"variance = \"+str(variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "N": "5"
    }
   },
   "source": [
    "### Visualize the Result\n",
    "\n",
    "The plot below shows the estimate (error bar equals +/- 1 standard deviation) and the sampled points. For the {{N}} samples closest to the estimate the kriging weights are shown.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(z.x, z.por, \n",
    "         \"o--\", label=\"samples\")\n",
    "plt.scatter((u[0]), (estimation), \n",
    "            c=\"red\", label=\"estimate\")\n",
    "plt.errorbar((u[0]), (estimation), yerr = sqrt(float(variance)), \n",
    "             fmt=\"r\", label=\"standard deviation\")\n",
    "\n",
    "offset = 0.05\n",
    "for i in range(len(weights)):\n",
    "    plt.text(P_n[i,0]+offset, \n",
    "             P_n[i,2]+offset, \n",
    "             \"{:.2f}\".format(float(weights[i])))\n",
    "\n",
    "ylabel('Value')\n",
    "xlabel('Easting [m]')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
