{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMPLE KRIGING IN PYTHON - 1D Application\n",
    "\n",
    "*This Notebook is based on an original Post from Connor Johnson, the original post is found here:\n",
    "http://connor-johnson.com/2014/03/20/simple-kriging-in-python/. It has been transferred to a Jupyter Notebook to make it more interactive.*\n",
    "\n",
    "*Changes being made:*\n",
    "+ *using a common variogram function*\n",
    "+ *calculation of variance map* \n",
    "+ *some code structure*\n",
    "\n",
    "*The example data is modified to represent a quasi-1D distribution (along the x-axis), to improve comprehensibility. Visualisation has been changed to consider this, and puts an additional focus on the uncertainty of the prediction*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post I will work through an example of Simple Kriging. Kriging is a set of techniques for interpolation. It differs from other interpolation techniques in that it sacrifices smoothness for the integrity of sampled points. Most interpolation techniques will over or undershoot the value of the function at sampled locations, but kriging honors those measurements and keeps them fixed. In future posts I would like to cover other types of kriging, other semivariaogram models, and colocated co-kriging. Until then, I’m keeping relatively up to date code at my GitHub project, geostatsmodels. (https://github.com/cjohnson318/geostatsmodels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:08:29.220000Z",
     "start_time": "2018-02-26T20:08:22.254000Z"
    }
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "import numpy as np\n",
    "from pandas import DataFrame, Series\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['figure.figsize'] = [16 / 1.5, 10 / 1.5]   # inch / cm = 2.54\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['savefig.bbox'] = 'tight'\n",
    "# plt.rcParams['savefig.frameon'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The data used in this exercise is in a zip file at this site. (Click on Geostatistics Resources.) I have adapted my material from the Kriging document on the same site. My approach will focus more on programming. First we will import some modules and then load the data and parse it,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:08:29.235000Z",
     "start_time": "2018-02-26T20:08:29.224000Z"
    }
   },
   "outputs": [],
   "source": [
    "zraw = open( 'example_data/ZoneA.dat','r' ).readlines()\n",
    "zraw = [ i.strip().split() for i in zraw[10:] ]\n",
    "zraw = np.array( zraw, dtype=np.float )\n",
    "zraw = DataFrame( zraw, columns=['x','y','thk','por','perm','lperm','lpermp','lpermr'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we need to reduce the data, and only choose values within a certain intervall for y, and create a quasi-1D Dataset by zeroing the y-coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:08:29.424000Z",
     "start_time": "2018-02-26T20:08:29.238000Z"
    }
   },
   "outputs": [],
   "source": [
    "z = zraw  # create copy of raw data\n",
    "\n",
    "# reduce dataset, plot as 2D\n",
    "ymean = 7500\n",
    "yinterval = 2000\n",
    "\n",
    "fig, ax = subplots()\n",
    "ax.scatter( z.x, z.y, c=z.por, cmap='gray' )\n",
    "ax.plot((-1500,22000),(ymean - yinterval / 2, ymean - yinterval / 2), \"r--\")\n",
    "ax.plot((-1500,22000),(ymean + yinterval / 2, ymean + yinterval / 2), \"r--\")\n",
    "ax.plot((-1500,22000),(ymean, ymean), \"r-\")\n",
    "ax.set_aspect(1)\n",
    "xlim(-1500,22000)\n",
    "ylim(-1500,17500)\n",
    "xlabel('Easting [m]')\n",
    "ylabel('Northing [m]')\n",
    "title('Porosity %') ;\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:08:29.433000Z",
     "start_time": "2018-02-26T20:08:29.428000Z"
    }
   },
   "outputs": [],
   "source": [
    "# apply a trend to the samples\n",
    "z.por += 0.0005 * z.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:08:29.742000Z",
     "start_time": "2018-02-26T20:08:29.436000Z"
    }
   },
   "outputs": [],
   "source": [
    "z = z.loc[z.y > ymean - yinterval / 2]\n",
    "z = z.loc[z.y < ymean + yinterval / 2]\n",
    "\n",
    "# reduce to quasi 1-D, plot as 1D\n",
    "z.y = 0.\n",
    "z = z.sort_values(by=\"x\")\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.scatter( z.x, z.y, c=z.por, cmap='gray' )\n",
    "ylabel('Northing [m]')\n",
    "title('Porosity %') ;\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(z.x, z.por, \".-\")\n",
    "ylabel('Value')\n",
    "xlabel('Easting [m]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Semivariogram\n",
    "\n",
    "### Theory\n",
    "\n",
    "The semivariogram encodes data about spatial variance over the region at a given distance or lag. We generally expect data points that are close together spatially to share other characteristics, and we expect points that are separated by greater distances to have lesser correlation. The semivariogram allows us to model the similarity points in a field as a function of distance. The semivariogram is given by,\n",
    "\n",
    "$$\\begin{equation*} \\hat{\\gamma}(h) = \\dfrac{1}{2N(h)} \\displaystyle \\sum_{N(h)} ( z_{i} - z_{j} )^{2} \\end{equation*}$$ (Equation 1)\n",
    "\n",
    "Here, h is distance specified by the user, and z_{i} and z_{j} are two points that are separated spatially by h. The N(h) term is the number of points we have that are separated by the distance h. The semivariogram then is the sum of squared differences between values separated by a distance h. As an aside, contrast this with the formulation for variance,\n",
    "\n",
    "$$\\begin{equation*} s = \\dfrac{1}{N-1} \\displaystyle \\sum_{k=1}^{N} (z_{k} - \\hat{\\mu} )^{2} \\end{equation*}$$ (Equation 2)\n",
    "\n",
    "Here, $N$ is the number of data points, $\\hat{\\mu}$ is the sample mean, and $z_{k}$ is a data point. For sample variance, we are taking the squared difference between data points and the mean, and in the semivariogram we are taking the squared difference between data points separated by distance h. We can write some functions to calculate the semivariogram at one lag, and then at multiple lags as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:08:29.762000Z",
     "start_time": "2018-02-26T20:08:29.745000Z"
    }
   },
   "outputs": [],
   "source": [
    "def SVh( P, h, bw ):\n",
    "    '''\n",
    "    Experimental semivariogram for a single lag\n",
    "    '''\n",
    "    pd = squareform( pdist( P[:,:2] ) )\n",
    "    N = pd.shape[0]\n",
    "    Z = list()\n",
    "    for i in range(N):\n",
    "        for j in range(i+1,N):\n",
    "            if( pd[i,j] >= h-bw )and( pd[i,j] <= h+bw ):\n",
    "                Z.append( ( P[i,2] - P[j,2] )**2.0 )\n",
    "    return np.sum( Z ) / ( 2.0 * len( Z ) )\n",
    " \n",
    "def SV( P, hs, bw ):\n",
    "    '''\n",
    "    Experimental variogram for a collection of lags\n",
    "    '''\n",
    "    sv = list()\n",
    "    for h in hs:\n",
    "        sv.append( SVh( P, h, bw ) )\n",
    "    sv = [ [ hs[i], sv[i] ] for i in range( len( hs ) ) if sv[i] > 0 ]\n",
    "    return np.array( sv ).T\n",
    " \n",
    "def C( P, h, bw ):\n",
    "    '''\n",
    "    Calculate the sill\n",
    "    '''\n",
    "    c0 = np.var( P[:,2] )\n",
    "    if h == 0:\n",
    "        return c0\n",
    "    return c0 - SVh( P, h, bw )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The C() function is the covariance function, and will be used later. Let us now calculate and plot the semivariogram,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical Semivariogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:08:29.932000Z",
     "start_time": "2018-02-26T20:08:29.766000Z"
    }
   },
   "outputs": [],
   "source": [
    "# part of our data set recording porosity\n",
    "P = np.array( z[['x','y','por']] )\n",
    "# bandwidth, plus or minus 250 meters\n",
    "bw = 500\n",
    "# lags in 500 meter increments from zero to 10,000\n",
    "hs = np.arange(0,10500,bw)\n",
    "sv = SV( P, hs, bw )\n",
    "plot( sv[0], sv[1], '.-' )\n",
    "xlabel('Lag [m]')\n",
    "ylabel('Semivariance')\n",
    "title('Sample Semivariogram') ;\n",
    "#savefig('sample_semivariogram.png',fmt='png',dpi=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semivariogram models\n",
    "\n",
    "Now that we’ve calculated the semivariogram, we will need to fit a model to the data. There are three popular models, the spherical, exponential, and the Gaussian. First, we will present a function named opt() for determining the optimal value a for the spherical model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:08:29.943000Z",
     "start_time": "2018-02-26T20:08:29.935000Z"
    }
   },
   "outputs": [],
   "source": [
    "def opt( fct, x, y, C0, parameterRange=None, meshSize=1000 ):\n",
    "    if parameterRange == None:\n",
    "        parameterRange = [ x[1], x[-1] ]\n",
    "    mse = np.zeros( meshSize )\n",
    "    a = np.linspace( parameterRange[0], parameterRange[1], meshSize )\n",
    "    for i in range( meshSize ):\n",
    "        mse[i] = np.mean( ( y - fct( x, a[i], C0 ) )**2.0 )\n",
    "    return a[ mse.argmin() ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The opt() function finds the optimal parameter for fitting a spherical model to the semivariogram data. The spherical model is given by the function spherical(). On the last line we see that spherical() returns itself in a map() function, which seems odd. The idea is that the input h can be a single float value, or list or NumPy array of floats. If h is a single value, then line 9 is called. If h is a list or an array (an iterable) then line 17 is called, which applies line 9 to each value of h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:08:29.963000Z",
     "start_time": "2018-02-26T20:08:29.947000Z"
    }
   },
   "outputs": [],
   "source": [
    "def gaussian( h, a, C0 ):\n",
    "    '''\n",
    "    Gaussian model of the semivariogram\n",
    "    '''\n",
    "    # if h is a single digit\n",
    "    if type(h) == np.float64:\n",
    "        # calculate the spherical function\n",
    "        return C0 * (1 - exp(-3*h**2/a**2))\n",
    "        \n",
    "    # if h is an iterable\n",
    "    else:\n",
    "        # calcualte the gaussian function for all elements\n",
    "        a = np.ones( h.size ) * a\n",
    "        C0 = np.ones( h.size ) * C0\n",
    "        return list(map( gaussian, h, a, C0 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:08:29.982000Z",
     "start_time": "2018-02-26T20:08:29.967000Z"
    }
   },
   "outputs": [],
   "source": [
    "def exponential( h, a, C0 ):\n",
    "    '''\n",
    "    Exponential model of the semivariogram\n",
    "    '''\n",
    "    # if h is a single digit\n",
    "    if type(h) == np.float64:\n",
    "        # calculate the exponential function\n",
    "        return C0 * (1 - exp(-3*h/a))\n",
    "        \n",
    "    # if h is an iterable\n",
    "    else:\n",
    "        # calcualte the exponential function for all elements\n",
    "        a = np.ones( h.size ) * a\n",
    "        C0 = np.ones( h.size ) * C0\n",
    "        return list(map( exponential, h, a, C0 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:08:30.001000Z",
     "start_time": "2018-02-26T20:08:29.984000Z"
    }
   },
   "outputs": [],
   "source": [
    "def spherical( h, a, C0 ):\n",
    "    '''\n",
    "    Spherical model of the semivariogram\n",
    "    '''\n",
    "    # if h is a single digit\n",
    "    if type(h) == np.float64:\n",
    "        # calculate the spherical function\n",
    "        if h <= a:\n",
    "            return C0*( 1.5*h/a - 0.5*(h/a)**3.0 )\n",
    "        else:\n",
    "            return C0\n",
    "    # if h is an iterable\n",
    "    else:\n",
    "        # calcualte the spherical function for all elements\n",
    "        a = np.ones( h.size ) * a\n",
    "        C0 = np.ones( h.size ) * C0\n",
    "        return list(map( spherical, h, a, C0 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, cvmodel() fits a model to the semivariogram data and returns a covariance method named covfct()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:08:30.021000Z",
     "start_time": "2018-02-26T20:08:30.003000Z"
    }
   },
   "outputs": [],
   "source": [
    "def cvmodel( P, model, hs, bw ):\n",
    "    '''\n",
    "    Input:  (P)      ndarray, data\n",
    "            (model)  modeling function\n",
    "                      - spherical\n",
    "                      - exponential\n",
    "                      - gaussian\n",
    "            (hs)     distances\n",
    "            (bw)     bandwidth\n",
    "    Output: (covfct) function modeling the covariance\n",
    "    '''\n",
    "    # calculate the semivariogram\n",
    "    sv = SV( P, hs, bw )\n",
    "    # calculate the sill\n",
    "    C0 = C( P, hs[0], bw )\n",
    "    # calculate the optimal parameters\n",
    "    param = opt( model, sv[0], sv[1], C0 )\n",
    "    # return a covariance function\n",
    "    covfct = lambda h, a=param: C0 - model( h, a, C0 )\n",
    "    return covfct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we’ll plot our model and see if it represents our data well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:08:31.194000Z",
     "start_time": "2018-02-26T20:08:30.732000Z"
    }
   },
   "outputs": [],
   "source": [
    "cv_gaussian = cvmodel( P, model=gaussian, hs=np.arange(0,10500,500), bw=500 )\n",
    "cv_exponential = cvmodel( P, model=exponential, hs=np.arange(0,10500,500), bw=500 )\n",
    "cv_spherical = cvmodel( P, model=spherical, hs=np.arange(0,10500,500), bw=500 )\n",
    "\n",
    "C0 = C( P, hs[0], bw )  # Sill\n",
    "\n",
    "title('Variogram Model')\n",
    "plot(sv[0], sv[1], 'o--', label=\"empirical semivariogram\")\n",
    "plot(sv[0], C0 - cv_gaussian( sv[0] ), label=\"gaussian model\" )\n",
    "plot(sv[0], C0 - cv_exponential( sv[0] ), label=\"exponential model\" )\n",
    "plot(sv[0], C0 - cv_spherical( sv[0] ), label=\"spherical model\" )\n",
    "ylabel('Semivariance')\n",
    "xlabel('Lag [m]')\n",
    "plt.legend()\n",
    "#savefig('semivariogram_model.png',fmt='png',dpi=200)\n",
    "\n",
    "sp = cv_gaussian\n",
    "\n",
    "sv = SV( P, hs=np.arange(0,10500,500), bw=500 )\n",
    "a = opt( spherical, sv[0], sv[1], C0 )  # lag\n",
    "\n",
    "plt.plot((0,a,a),(C0,C0,0), \":\", c=\"grey\")\n",
    "plt.text(0,C0+0.02,\"sill {:.2e}\".format(C0),color=\"grey\")\n",
    "plt.text(a,0,\"lag {:.2e}\".format(a), rotation=270, verticalalignment='bottom',color=\"grey\")\n",
    "\n",
    "print(\"sill: {:.2f}, lag: {:.2f}\".format(C0,a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Kriging\n",
    "\n",
    "\n",
    "Now that we have a model for the semivariogram, we can write a function to perform the kriging. The fundamental relationship is a matrix equation,\n",
    "\n",
    "$$\\begin{equation*} K \\lambda = k \\Rightarrow \\lambda = K^{-1} k \\end{equation*} $$ \n",
    "\n",
    "Here, $K$ is a matrix of covariances calculated using the spherical model, $\\lambda$ is a vector of simple kriging weights, and $k$ is the vector of covariances between the data points and an unsampled point. Our kriging function takes the data set $P$, the model, the distances hs, the bandwidth bw, the coordinates of the unsampled point u, and the number of surrounding points N to use in the calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation (the actual Kriging process)\n",
    "\n",
    "Here, we’ll calculate the kriging estimate at a number of unsampled points. We create a linear vector of x-values, and then make a prediction of the value for each of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:08:32.339000Z",
     "start_time": "2018-02-26T20:08:32.302000Z"
    }
   },
   "outputs": [],
   "source": [
    "def krige( P, covfct, u, N, trendf=None ):\n",
    "    '''\n",
    "    Input  (P)     ndarray, data\n",
    "           (covfct) modeling function\n",
    "                    - spherical\n",
    "                    - exponential\n",
    "                    - gaussian\n",
    "           (u)     unsampled point\n",
    "           (N)     number of neighboring\n",
    "                   points to consider\n",
    "    '''\n",
    "\n",
    "    assert N < len(P) + 1, \"Number of Neighbors greater than number of data points\"\n",
    "    \n",
    "    # mean of the variable\n",
    "    mu = np.mean( P[:,2] )\n",
    " \n",
    "    # distance between u and each data point in P\n",
    "    d = np.sqrt( ( P[:,0]-u[0] )**2.0 + ( P[:,1]-u[1] )**2.0 )\n",
    "    # add these distances to P\n",
    "    P = np.vstack(( P.T, d )).T\n",
    "    # sort P by these distances\n",
    "    # take the first N of them\n",
    "    P_n = P[d.argsort()[:N]]\n",
    " \n",
    "    # apply the covariance model to the distances\n",
    "    k = covfct( P_n[:,3] )\n",
    "    # cast as a matrix\n",
    "    k = np.matrix( k ).T\n",
    "    \n",
    "    # calculate t(x)\n",
    "    t_x = trendf(u[0])\n",
    "    #print(t_x)\n",
    "\n",
    "    # T(X)\n",
    "    T = np.apply_along_axis(trendf, 0, P_n[:,0])\n",
    "    #print(T)\n",
    " \n",
    "    # form a matrix of distances between existing data points\n",
    "    K = squareform( pdist( P_n[:,:2] ) )\n",
    "    # apply the covariance model to these distances\n",
    "    K = covfct( K.ravel() )\n",
    "    # re-cast as a NumPy array -- thanks M.L.\n",
    "    K = np.array( K )\n",
    "    # reshape into an array\n",
    "    K = K.reshape(N,N)\n",
    "    # cast as a matrix\n",
    "    K = np.matrix( K )\n",
    " \n",
    "    K += np.identity(K.shape[0]) * 1.0\n",
    "\n",
    "    # calculate the kriging weights\n",
    "    weights = np.linalg.inv( K ) * k\n",
    "    weights = np.array( weights )\n",
    " \n",
    "    # calculate the residuals\n",
    "    residuals = P_n[:,2] #- mu\n",
    " \n",
    "    # calculate the estimation\n",
    "    estimation = t_x + np.dot( weights.T, (residuals - T )) #+ mu\n",
    "    \n",
    "    return (float( estimation ), k, K, weights, P_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:08:32.364000Z",
     "start_time": "2018-02-26T20:08:32.341000Z"
    }
   },
   "outputs": [],
   "source": [
    "P[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:08:32.378000Z",
     "start_time": "2018-02-26T20:08:32.367000Z"
    }
   },
   "outputs": [],
   "source": [
    "def testfct2D(coord, a=1., b=1., m=0.):\n",
    "    x, y = coord\n",
    "    \n",
    "    t = a*x + b*y + m\n",
    "    print(t)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:08:32.404000Z",
     "start_time": "2018-02-26T20:08:32.381000Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "np.apply_along_axis(testfct2D, 1, P[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:08:34.507000Z",
     "start_time": "2018-02-26T20:08:32.406000Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the intervall \n",
    "\n",
    "X0, X1 = -5000., 40000.  # min X, max X\n",
    "n = 1000  # number of samples\n",
    "nn = 5  # number of neighbors for Kriging\n",
    "\n",
    "dx = (X1-X0)/n\n",
    "print(\"sampling resolution: {:.2f}\".format(dx))\n",
    "\n",
    "# create progress indicator\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "wdgt = FloatProgress(min=0, max=n, description=\"Running Kriging ... \")\n",
    "display(wdgt)\n",
    "\n",
    "a, b = np.polyfit(P[:,0], P[:,2], 1)\n",
    "print(\"trend f(x) = {} x + {}\".format(a,b))\n",
    "trendf = lambda x: a * x + b\n",
    "\n",
    "# perform Krigin\n",
    "Z = np.zeros(n)\n",
    "V = np.zeros(n)\n",
    "for i in range(n):\n",
    "    wdgt.value += 1\n",
    "    h, k, K, weights, P_n = krige( P, sp, (dx*i, 0), nn, trendf=trendf)\n",
    "    Z[i] = h\n",
    "    v = C0 - np.dot(k.T, weights)\n",
    "    V[i] = max(v,0)  # computation accuracy may lead to small negative variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T19:16:35.647000Z",
     "start_time": "2018-02-26T19:16:35.642000Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Estimator - 1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate and Uncertainty\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:08:36.135000Z",
     "start_time": "2018-02-26T20:08:35.059000Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.subplot(211)\n",
    "plt.title(\"Estimation\")\n",
    "plt.fill_between([i*dx for i in range(n)], Z-2*np.sqrt(V), Z+3*np.sqrt(V), color='green', alpha=0.1, label=\"+/- 3 stdev\")\n",
    "plt.fill_between([i*dx for i in range(n)], Z-2*np.sqrt(V), Z+2*np.sqrt(V), color='green', alpha=0.2, label=\"+/- 2 stdev\")\n",
    "plt.fill_between([i*dx for i in range(n)], Z-1*np.sqrt(V), Z+1*np.sqrt(V), color='green', alpha=0.3, label=\"+/- 1 stdev\")\n",
    "plt.plot([i*dx for i in range(n)], Z, \"g-\", label=\"best estimate\")\n",
    "plt.scatter(z.x, z.por, s=6, c=\"r\", label=\"sample\")\n",
    "plt.plot((X0, X1),(z.por.mean(), z.por.mean()), \"r-.\", alpha=0.3, label=\"mean of sample\")\n",
    "\n",
    "plt.plot(arange(0,50000),  np.apply_along_axis(trendf, 0, arange(0,50000)), label=\"trend function\")\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig(\"krigin1d-confidenceintervalls.png\")\n",
    "ylabel('Estimate []')\n",
    "lim = plt.ylim()\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.fill_between([i*dx for i in range(n)], 3*np.sqrt(V), -3*np.sqrt(V), color='green', alpha=0.1, label=\"+/- 3 stdev\")\n",
    "plt.fill_between([i*dx for i in range(n)], 2*np.sqrt(V), -2*np.sqrt(V), color='green', alpha=0.2, label=\"+/- 2 stdev\")\n",
    "plt.fill_between([i*dx for i in range(n)], 1*np.sqrt(V), -1*np.sqrt(V), color='green', alpha=0.3, label=\"+/- 1 stdev\")\n",
    "\n",
    "plt.plot((X0, X1),(1*np.sqrt(C0), 1*np.sqrt(C0)), \"y--\", label=\"sqrt(sill)\")\n",
    "plt.plot((X0, X1),(0,0), \"grey\")\n",
    "plt.plot((X0, X1),(-1*np.sqrt(C0), -1*np.sqrt(C0)), \"y--\")\n",
    "plt.ylim(lim - (lim[0] + lim[1])/2)  # set variance y-scale equal to value, but centered to zero\n",
    "plt.scatter(z.x, np.zeros_like(z.x), s=6, c=\"r\", label=\"sample\")\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "ylabel('Uncertainty []')\n",
    "xlabel('Predictor')\n",
    "\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "variables": {
     "nn": "5"
    }
   },
   "source": [
    "## Kriging Weights Analysis\n",
    "\n",
    "Use the sliders to change the X-Coordinate of the sampled point and the number of neighbors considered in Kriging.\n",
    "Note: The background curves are not updated (computed with the original value of {{nn}} neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:08:36.510000Z",
     "start_time": "2018-02-26T20:08:36.150000Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "#%matplotlib inline\n",
    "#plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['figure.figsize'] = [16 / 1.5, 10 / 1.5]   # inch / cm = 2.54\n",
    "\n",
    "from ipywidgets import *\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "def drawfig(fig, x, nn):\n",
    "    \n",
    "    u = (x, 0)  # (x,y) - coordinates of unsampled points\n",
    "\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    #plt.fill_between([i*dx for i in range(n)], Z-2*np.sqrt(V), Z+3*np.sqrt(V), color='green', alpha=0.1, label=\"+/- 3 stdev\")\n",
    "    ax.fill_between([i*dx for i in range(n)], Z-2*np.sqrt(V), Z+2*np.sqrt(V), color='green', alpha=0.2, label=\"+/- 2 stdev\")\n",
    "    ax.fill_between([i*dx for i in range(n)], Z-1*np.sqrt(V), Z+1*np.sqrt(V), color='green', alpha=0.3, label=\"+/- 1 stdev\")\n",
    "    ax.plot([i*dx for i in range(n)], Z, \"g-\", label=\"estimator\")\n",
    "    ax.scatter(z.x, z.por, s=6, c=\"r\", label=\"sample\")\n",
    "    ax.plot((X0, X1),(z.por.mean(), z.por.mean()), \"r-.\", alpha=0.3, label=\"mean of sample\")\n",
    "\n",
    "    #ax.legend(loc='upper right')\n",
    "\n",
    "    estimation, k, K, weights, P_n = krige( P, sp, u, nn, trendf=trendf )\n",
    "    variance = C0 - np.dot( weights.T, k )\n",
    "\n",
    "\n",
    "    ax.plot(z.x, z.por, \n",
    "             \"o--\", label=\"samples\")\n",
    "    ax.scatter((x), (estimation), \n",
    "                c=\"red\", label=\"estimate\")\n",
    "    ax.errorbar((u[0]), (estimation), yerr = sqrt(float(variance)), \n",
    "                 fmt=\"r\", label=\"standard deviation\")\n",
    "\n",
    "    offset = 0.05\n",
    "    for i in range(len(weights)):\n",
    "        ax.text(P_n[i,0]+offset, \n",
    "                P_n[i,2]+offset, \n",
    "                \"{:.2f}\".format(float(weights[i])),\n",
    "                color=\"black\")\n",
    "    \n",
    "drawfig(fig, 6000, nn)\n",
    "\n",
    "minx = P[:,0].min() - 2*a\n",
    "maxx = P[:,0].max() + 2*a\n",
    "\n",
    "@interact(x=(minx, maxx), nn=(1,len(P)))\n",
    "def updatefig(x, nn):\n",
    "    fig.clear()\n",
    "    drawfig(fig, x, nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
